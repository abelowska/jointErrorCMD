{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dae3fb2-92e9-4906-a206-f991c6525026",
   "metadata": {},
   "source": [
    "# HDDM models informed with EEG and pre-trial accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876714c-134c-498c-9f6e-3c97854b6299",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0f725-7cfb-4f24-9c14-c81701ce5a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmdstanpy\n",
    "cmdstanpy.install_cmdstan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9bb4b-ac5f-4f3d-852d-3df5a5681907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmdstanpy import CmdStanModel\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from contextlib import redirect_stdout\n",
    "import seaborn as sns\n",
    "# set path to CMD Stan\n",
    "# set_cmdstan_path('/stan/math_HOW-TO-USE/cmdstan-ddm-7pm')\n",
    "# cmdstan_path()\n",
    "\n",
    "# set Stan globals\n",
    "# os.environ['STAN_NUM_THREADS'] = \"12\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca38ec-d3d7-4982-9bf4-b16806718cde",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d7fea-2bc1-426b-92fa-bae25469fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'drift_boundary_pre2_ncond_tbb' \n",
    "model_name = f'wiener_{name}_model.stan'\n",
    "\n",
    "print(f'Processing model: {model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ef4de-40d6-4d57-b34d-79cb6d8b210b",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c0693-b831-4b07-8ad8-145081bf0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(stan_file, max_retries=5, retry_delay=5):\n",
    "    model = None\n",
    "    compiled = False\n",
    "    retries=0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            model = CmdStanModel(\n",
    "                stan_file=stan_file, \n",
    "                cpp_options={'STAN_THREADS': True}, \n",
    "                force_compile=True\n",
    "            )\n",
    "            compiled = True\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error compiling model: {e}\")\n",
    "            retries+=1\n",
    "            if retries >= max_retries:\n",
    "                print(\"Max retries reached. Exiting.\")\n",
    "                return None, compiled\n",
    "            print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "    if not compiled:\n",
    "        return None, compiled\n",
    "    else:\n",
    "        return model, compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21643adc-d82e-4de2-89da-0cdd568fb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_file = os.path.join('../models/TBB_models', model_name)\n",
    "hddm_model, compiled = compile_model(stan_file)\n",
    "compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101643a8-9ae5-4ea9-ab20-d114ebec677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm_model.exe_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5dea9-4981-4ff4-86fa-747834876140",
   "metadata": {},
   "source": [
    "## Define data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee657b-0989-42e8-bed5-85d0dc6ebd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join('../data/', 'stahl_acc_data_standarized.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e308e05-2258-45a9-8896-f903dfcec753",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211909b-4cce-4b45-9177-c720e453c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21546990-80f4-47ea-bd64-fc231e84fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(\n",
    "    {\n",
    "        'participant_index': data['participant'],\n",
    "         'rt': abs(np.array(data['y']))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea823b-4a0f-402d-beb9-b8caeb8c20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c04b47-530c-4839-8d4e-558154fa3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,):\n",
    "    display(data_df.groupby('participant_index').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9e878-e081-450d-8da8-ca2c7c49a70c",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74811420-b760-4bc6-9b23-54e901b81fbe",
   "metadata": {},
   "source": [
    "Fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa60473-3fc9-40ad-82dc-c6c191f8ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chains = 1\n",
    "warmup = 10\n",
    "num_samples = 10\n",
    "thin=5\n",
    "adapt_delta=0.99\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ba251-ef78-4577-bef0-157b90b94354",
   "metadata": {},
   "source": [
    "Define initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccacb0b6-4427-4b99-b1c3-bca1f492e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_participants = data['n_participants']\n",
    "\n",
    "min_rt = np.zeros(n_participants)\n",
    "for idx, participant_idx in enumerate(np.unique(data['participant'])):\n",
    "    participant_rts = data_df[data_df['participant_index'] == participant_idx]['rt'].to_numpy()\n",
    "    min_rt[idx] = np.min(abs(participant_rts))\n",
    "\n",
    "initials = []\n",
    "for c in range(0, num_chains):\n",
    "    chain_init = {               \n",
    "        'ter_sd': np.random.uniform(.01, .2),\n",
    "        'alpha_sd': np.random.uniform(.01, 1.),\n",
    "        'alpha_cond_sd': np.random.uniform(.01, 1.), # <- was 0.5\n",
    "        'delta_sd': np.random.uniform(.1, 3.),\n",
    "        'delta_cond_sd': np.random.uniform(.1, 3.),\n",
    "        \n",
    "        'alpha_ne_sd': np.random.uniform(.01, .2), # <- works quite nice with .01, .2, works with .01, 1 \n",
    "        'delta_ne_sd': np.random.uniform(.001, .2), # 0.2 ###########\n",
    "\n",
    "        'alpha_ne_pre_acc_sd': np.random.uniform(.01, .2), # <- works quite nice with .01, .2, works with .01, 1 \n",
    "        'delta_ne_pre_acc_sd': np.random.uniform(.001, .2), # 0.2 ###########\n",
    "\n",
    "        'ter': np.random.uniform(0.05, .4),\n",
    "        'alpha': np.random.uniform(1, 2), #0.2 ## <- does not work with < 1\n",
    "        'alpha_cond': np.random.uniform(-.5, .5), # <- was -.1, .1 and works a little bit better\n",
    "        'delta': np.random.uniform(-4., 4.),\n",
    "        'delta_cond': np.random.uniform(-4., 4.),\n",
    "\n",
    "        'alpha_ne': np.random.uniform(-.05, .05), # <- does not work with -0.1, 0.1\n",
    "        'alpha_pre_acc': np.random.uniform(-0.1, .1), \n",
    "        'alpha_ne_pre_acc': np.random.uniform(-.05, .05), # does not work with -0.1, 0.1\n",
    "        'alpha_ne_cond': np.random.uniform(-.05, .05), # <- does not work with -0.1, 0.1\n",
    "        'alpha_pre_acc_cond': np.random.uniform(-0.1, .1), \n",
    "        'alpha_ne_pre_acc_cond': np.random.uniform(-.05, .05), # does not work with -0.1, 0.1\n",
    "\n",
    "        'delta_ne': np.random.uniform(-.1, .1),\n",
    "        'delta_pre_acc': np.random.uniform(-.5, .5),\n",
    "        'delta_ne_pre_acc': np.random.uniform(-.1, .1),\n",
    "        'delta_ne_cond': np.random.uniform(-.1, .1),\n",
    "        'delta_pre_acc_cond': np.random.uniform(-.5, .5),\n",
    "        'delta_ne_pre_acc_cond': np.random.uniform(-.1, .1),\n",
    "        \n",
    "        'participants_ter': np.random.uniform(0.05, .4, size=n_participants),\n",
    "        'participants_alpha': np.random.uniform(1, 2., size=n_participants), ## <- does not work with <1\n",
    "        'participants_alpha_cond': np.random.uniform(-0.5, .5, size=n_participants), # <- was -.1, .1 and works a little bit better \n",
    "        'participants_delta': np.random.uniform(-4., 4., size=n_participants),\n",
    "        'participants_delta_cond': np.random.uniform(-4., 4., size=n_participants),\n",
    "        \n",
    "        'participants_alpha_ne': np.random.uniform(-.05, .05, size=n_participants),\n",
    "        'participants_delta_ne': np.random.uniform(-.1, .1, size=n_participants), #########\n",
    "\n",
    "        'participants_alpha_ne_pre_acc': np.random.uniform(-.05, .05, size=n_participants),\n",
    "        'participants_delta_ne_pre_acc': np.random.uniform(-.05, .05, size=n_participants), #########\n",
    "    }\n",
    "    for p in range(0, n_participants):\n",
    "        chain_init['participants_ter'][p] = np.random.uniform(0., min_rt[p]/2)\n",
    "\n",
    "    initials.append(chain_init)\n",
    "\n",
    "print(min_rt)\n",
    "# n_participants = data['n_participants']\n",
    "\n",
    "# min_rt = np.zeros(n_participants)\n",
    "# for idx, participant_idx in enumerate(np.unique(data['participant'])):\n",
    "#     participant_rts = data_df[data_df['participant_index'] == participant_idx]['rt'].to_numpy()\n",
    "#     min_rt[idx] = np.min(abs(participant_rts))\n",
    "\n",
    "# initials = []\n",
    "# for c in range(0, num_chains):\n",
    "#     chain_init = {               \n",
    "#         'ter_sd': np.random.uniform(.01, .2),\n",
    "#         'varsigma_sd': np.random.uniform(.01, 1.),\n",
    "#         'varsigma_cond_sd': np.random.uniform(.01, 1.), # <- was 0.5\n",
    "#         'delta_sd': np.random.uniform(.1, 3.),\n",
    "#         'delta_cond_sd': np.random.uniform(.1, 3.),\n",
    "        \n",
    "#         'varsigma_ne_sd': np.random.uniform(.01, .2), # <- works quite nice with .01, .2, works with .01, 1 \n",
    "#         'delta_ne_sd': np.random.uniform(.001, .2), # 0.2 ###########\n",
    "\n",
    "#         'varsigma_ne_pre_acc_sd': np.random.uniform(.01, .2), # <- works quite nice with .01, .2, works with .01, 1 \n",
    "#         'delta_ne_pre_acc_sd': np.random.uniform(.001, .2), # 0.2 ###########\n",
    "\n",
    "#         'ter': np.random.uniform(0.05, .4),\n",
    "#         'varsigma': np.random.uniform(1, 2), #0.2 ## <- does not work with < 1\n",
    "#         'varsigma_cond': np.random.uniform(-.5, .5), # <- was -.1, .1 and works a little bit better\n",
    "#         'delta': np.random.uniform(-4., 4.),\n",
    "#         'delta_cond': np.random.uniform(-4., 4.),\n",
    "\n",
    "#         'varsigma_ne': np.random.uniform(-.05, .05), # <- does not work with -0.1, 0.1\n",
    "#         'varsigma_pre_acc': np.random.uniform(-0.1, .1), \n",
    "#         'varsigma_ne_pre_acc': np.random.uniform(-.05, .05), # does not work with -0.1, 0.1\n",
    "#         'varsigma_ne_cond': np.random.uniform(-.05, .05), # <- does not work with -0.1, 0.1\n",
    "#         'varsigma_pre_acc_cond': np.random.uniform(-0.1, .1), \n",
    "#         'varsigma_ne_pre_acc_cond': np.random.uniform(-.05, .05), # does not work with -0.1, 0.1\n",
    "\n",
    "#         'delta_ne': np.random.uniform(-.1, .1),\n",
    "#         'delta_pre_acc': np.random.uniform(-.5, .5),\n",
    "#         'delta_ne_pre_acc': np.random.uniform(-.1, .1),\n",
    "#         'delta_ne_cond': np.random.uniform(-.1, .1),\n",
    "#         'delta_pre_acc_cond': np.random.uniform(-.5, .5),\n",
    "#         'delta_ne_pre_acc_cond': np.random.uniform(-.1, .1),\n",
    "        \n",
    "#         'participants_ter': np.random.uniform(0.05, .4, size=n_participants),\n",
    "#         'participants_varsigma': np.random.uniform(1, 2., size=n_participants), ## <- does not work with <1\n",
    "#         'participants_varsigma_cond': np.random.uniform(-0.5, .5, size=n_participants), # <- was -.1, .1 and works a little bit better \n",
    "#         'participants_delta': np.random.uniform(-4., 4., size=n_participants),\n",
    "#         'participants_delta_cond': np.random.uniform(-4., 4., size=n_participants),\n",
    "        \n",
    "#         'participants_varsigma_ne': np.random.uniform(-.05, .05, size=n_participants),\n",
    "#         'participants_delta_ne': np.random.uniform(-.1, .1, size=n_participants), #########\n",
    "\n",
    "#         'participants_varsigma_ne_pre_acc': np.random.uniform(-.05, .05, size=n_participants),\n",
    "#         'participants_delta_ne_pre_acc': np.random.uniform(-.05, .05, size=n_participants), #########\n",
    "#     }\n",
    "#     for p in range(0, n_participants):\n",
    "#         chain_init['participants_ter'][p] = np.random.uniform(0., min_rt[p]/2)\n",
    "\n",
    "#     initials.append(chain_init)\n",
    "\n",
    "# print(min_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe94d2-03c8-4b07-9ac9-e1681a9944ba",
   "metadata": {},
   "source": [
    "Perform fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f137d3c-f0ff-4b73-a124-27dd1618cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, data_file, name, max_retries=5, retry_delay=5):\n",
    "    fit = None\n",
    "    retries=0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            with open('jupyter_logs.txt', 'a') as f:\n",
    "                fit = model.sample(\n",
    "                    data=data_file,\n",
    "                    chains=num_chains, \n",
    "                    seed=random_state,\n",
    "                    thin=thin,\n",
    "                    adapt_delta=adapt_delta,\n",
    "                    inits=initials, \n",
    "                    iter_warmup=warmup, \n",
    "                    iter_sampling=num_samples,\n",
    "                    parallel_chains=num_chains,\n",
    "                    threads_per_chain= 12,\n",
    "                    max_treedepth=12,\n",
    "                    show_progress=True,\n",
    "                    show_console=True,\n",
    "                    output_dir=f'../../plgrid_results/ncond_models/stahl/acc/stahl_acc_ncond_{name}_1/'\n",
    "                )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error sampling model: {e}\")\n",
    "            retries+=1\n",
    "            if retries >= max_retries:\n",
    "                print(\"Max retries reached. Exiting.\")\n",
    "                return None\n",
    "            print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820bc26-af8a-4233-878b-4d76c635a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compiled:\n",
    "    fit = fit_model(\n",
    "        hddm_model,\n",
    "        data_file,\n",
    "        name,\n",
    "    )\n",
    "    \n",
    "\n",
    "# with open('jupyter_logs.txt', 'a') as f:\n",
    "#     with redirect_stdout(f):\n",
    "#         start = time.time()\n",
    "#         fit = hddm_model.sample(\n",
    "#             data=data_file,\n",
    "#             chains=num_chains, \n",
    "#             seed=random_state,\n",
    "#             thin=thin,\n",
    "#             adapt_delta=adapt_delta,\n",
    "#             inits=initials, \n",
    "#             iter_warmup=warmup, \n",
    "#             iter_sampling=num_samples,\n",
    "#             parallel_chains=num_chains,\n",
    "#             threads_per_chain= 12,\n",
    "#             max_treedepth=12,\n",
    "#             show_progress=True,\n",
    "#             show_console=True,\n",
    "#             output_dir=f'../../plgrid_results/ncond_models/stahl/acc/stahl_acc_ncond_{name}_1/'\n",
    "#         )\n",
    "#         end = time.time()\n",
    "\n",
    "# print(f'Fitting took: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2437c-263b-472c-baa8-e51f94ce7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit.diagnose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae5219-f869-4ce4-af58-162f4bdb0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad05720-fe5a-44ed-831b-7b7f7a4906c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(f'test_priors2_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660cab6-f6a4-4ce3-9106-970eacaa5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - changed initials (as boundary(and main effects - the same as boundary, no sd priors || 1.23\n",
    "# 6 - changed initials and main effects, and sd priors ||1.6 for delta_ne_sd\n",
    "# 5 - changed initials and main effects, no sd priors || 1.10 for delta_ne_sd\n",
    "# 4 - changed initials and main effects, and sd priors\n",
    "# 3 - ?\n",
    "# 2 - main effects, and sd priors\n",
    "# 1 - changed main effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca97f8b-acf5-4bf0-8898-fc6bc0cddde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df = fit.draws_pd()\n",
    "\n",
    "sns.lineplot(\n",
    "    data=fit_df,\n",
    "    x = 'iter__',\n",
    "    y = 'delta_ne_pre_acc_sd',\n",
    "    hue='chain__'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941d8e2-bc60-45aa-8ca3-30cabd71dd3a",
   "metadata": {},
   "source": [
    "Save the MCMC fit object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88454fc-3d6a-4c86-83f3-2b5da93adaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.save_csvfiles(dir=f'../plgrid_results/ncond_models_stahl/acc/stahl_acc_{name}_warmup-{warmup}_samples-{num_samples}_thin-{thin}-6/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfc348-091f-463d-93b8-edd955b94589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdstan_py",
   "language": "python",
   "name": "cmdstan_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
