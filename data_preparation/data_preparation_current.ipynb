{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcc82cafe9363b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Current dataset - Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b9fda2d5b150a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc79d4ee68bea47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:42:37.772090Z",
     "start_time": "2024-06-11T12:42:37.770369Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import truncnorm, beta, norm, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec85165e114df0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1. Read EEG and behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e75783ce5e051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:44:33.665347Z",
     "start_time": "2024-06-11T12:42:41.136597Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "paradigm = 'FLA'\n",
    "case = 'RE'\n",
    "\n",
    "data_path = f'../data/beh_eeg_{paradigm}/{paradigm}/preprocessed/wavelets_th-045/'\n",
    "data_df = pd.DataFrame()\n",
    "\n",
    "id_list = [item.split('.')[0] for item in os.listdir(data_path)]\n",
    "\n",
    "for participant_id in id_list:\n",
    "    participant_data_df = pd.read_pickle(f'{data_path}{participant_id}.pkl')\n",
    "    participant_data_df['ID'] = participant_id.split(\"_\")[1]\n",
    "    \n",
    "    # Create a DataFrame with the complete range of trial indices (1 to 300)\n",
    "    complete_trials = pd.DataFrame({'trial number': range(1, 301), 'ID': [participant_id.split(\"_\")[1]]*300})\n",
    "\n",
    "    # Merge the original DataFrame with the complete_trials DataFrame\n",
    "    merged_df = pd.merge(complete_trials, participant_data_df, on=['trial number', 'ID'], how='left')\n",
    "    \n",
    "    data_df = pd.concat([data_df, merged_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e071583060f4a23",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2. Featurize ERN: peak amplitude at FCz\n",
    "- EEG column in bad trials will be filled with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78cd082700cab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:45:12.506247Z",
     "start_time": "2024-06-11T12:44:33.664228Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "channel = 'FCz'\n",
    "\n",
    "data_df[f'ne_{channel}'] = data_df.apply(\n",
    "    lambda row: np.nan if pd.isna(row['drop_log']) or channel in row['drop_log'] else np.min(row['epoch'].get_data(picks=channel, tmin=0.0, tmax=0.1).flatten()),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data_df[f'ne_mean_{channel}'] = data_df.apply(\n",
    "    lambda row: np.nan if pd.isna(row['drop_log']) or channel in row['drop_log'] else np.mean(row['epoch'].get_data(picks=channel, tmin=0.0, tmax=0.1).flatten()),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "channel = 'Fz'\n",
    "\n",
    "data_df[f'ne_{channel}'] = data_df.apply(\n",
    "    lambda row: np.nan if pd.isna(row['drop_log']) or channel in row['drop_log'] else np.min(row['epoch'].get_data(picks=channel, tmin=0.0, tmax=0.1).flatten()),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data_df[f'ne_mean_{channel}'] = data_df.apply(\n",
    "    lambda row: np.nan if pd.isna(row['drop_log']) or channel in row['drop_log'] else np.mean(row['epoch'].get_data(picks=channel, tmin=0.0, tmax=0.1).flatten()),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eda3144aedc48e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:45:30.077990Z",
     "start_time": "2024-06-11T12:45:12.505463Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# drop column with epochs to better display df\n",
    "columns_to_drop = ['epoch']\n",
    "data_df = data_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb37d36-6af5-43cd-a2df-8d5e6eac43d3",
   "metadata": {},
   "source": [
    "Save full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e2402-72f6-4b15-b7cd-2bf74a5ffe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle('full_sample_current_dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aad042c0a7f854",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3. Mark bad participants (less than 6 trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309a2cc34ed8ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:45:30.619848Z",
     "start_time": "2024-06-11T12:45:30.080357Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cleared_data_df = data_df.copy(deep=True)\n",
    "\n",
    "ids = np.unique(data_df['ID'])\n",
    "n_clear_trails = 6\n",
    "\n",
    "for participant_id in ids:\n",
    "    participant_data = data_df[data_df['ID'] == participant_id]['ne_FCz'].to_numpy()\n",
    "    good_trials = np.count_nonzero(~np.isnan(participant_data.flatten()))\n",
    "    \n",
    "    if good_trials < n_clear_trails:\n",
    "        print(f\"Participant {participant_id} has {good_trials} good trial. Rejecting\")\n",
    "        cleared_data_df = cleared_data_df[cleared_data_df['ID'] != participant_id]        \n",
    "    \n",
    "cleared_data_df = cleared_data_df.reset_index()\n",
    "cleared_ids = np.unique(cleared_data_df['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89cadbb6e033640",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 4. Mark participants who have less than 6 error trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da5a00c8d0f9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:45:31.183494Z",
     "start_time": "2024-06-11T12:45:30.638229Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ids = np.unique(cleared_data_df['ID'])\n",
    "n_error = 6\n",
    "\n",
    "for participant_id in ids:\n",
    "    participant_data = cleared_data_df[cleared_data_df['ID'] == participant_id]\n",
    "    error_trials = participant_data[(participant_data['reaction'] == 'incorrect') & \n",
    "                                    (participant_data['ne_FCz'].notna())]\n",
    "    \n",
    "    if len(error_trials) < n_error:\n",
    "        print(f\"Participant {participant_id} has {len(error_trials)} erroneous trial. Rejecting\")\n",
    "        cleared_data_df = cleared_data_df[cleared_data_df['ID'] != participant_id]\n",
    "\n",
    "cleared_data_df = cleared_data_df.reset_index()\n",
    "cleared_ids = np.unique(cleared_data_df['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12754dd90c360277",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261baf4f6e1aa2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:45:31.620815Z",
     "start_time": "2024-06-11T12:45:31.226348Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "columns_name_mapping = {'trial number': 'trial_number'}\n",
    "cleared_data_df = cleared_data_df.rename(columns=columns_name_mapping)\n",
    "cleared_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11103d0f4fe42bc6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 5. Apply trial selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae64cad4437efbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:46:16.519486Z",
     "start_time": "2024-06-11T12:45:31.284421Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to check if rt exceeds 3*std\n",
    "def log_threshold(row, participant_means, participant_std):\n",
    "    participant_id = row['ID']\n",
    "    mean_log_rt = participant_means[participant_id]\n",
    "    std_log_rt = participant_std[participant_id]\n",
    "    upper_bound = mean_log_rt + 3*std_log_rt\n",
    "    lower_bound = mean_log_rt - 3*std_log_rt\n",
    "    \n",
    "    return (row['log_rt'] > upper_bound or row['log_rt'] < lower_bound), np.exp(upper_bound), np.exp(lower_bound)\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# create mapping IDs to ordinal 1-N number\n",
    "id_mapping = {old_id: new_id for new_id, old_id in enumerate(cleared_data_df['ID'].unique(), start=1)}\n",
    "\n",
    "# cast eeg to uV from V\n",
    "cleared_data_df['ne_Fz'] = cleared_data_df['ne_Fz'] * 1000000\n",
    "cleared_data_df['ne_mean_Fz'] = cleared_data_df['ne_mean_Fz'] * 1000000\n",
    "cleared_data_df['ne_FCz'] = cleared_data_df['ne_FCz'] * 1000000\n",
    "cleared_data_df['ne_mean_FCz'] = cleared_data_df['ne_mean_FCz'] * 1000000\n",
    "\n",
    "# add column with numerical indicator of accuracy\n",
    "cleared_data_df['acc'] = np.select(\n",
    "    [cleared_data_df['reaction'] == 'incorrect', cleared_data_df['reaction'] == 'correct', pd.isna(cleared_data_df['reaction'])],\n",
    "    [-1, 1, np.nan],\n",
    "    default=np.nan\n",
    ")\n",
    "\n",
    "# add column with numerical indicator of condition\n",
    "cleared_data_df['condition'] = np.select(\n",
    "    [cleared_data_df['trial_type'] == 'congruent', cleared_data_df['trial_type'] == 'incongruent', pd.isna(cleared_data_df['trial_type'])],\n",
    "    [1, -1, np.nan],\n",
    "    default=np.nan\n",
    ")\n",
    "\n",
    "# add column with condition index\n",
    "cleared_data_df['condition_index'] = np.select(\n",
    "    [cleared_data_df['trial_type'] == 'congruent', cleared_data_df['trial_type'] == 'incongruent', pd.isna(cleared_data_df['trial_type'])],\n",
    "    [1, 2, np.nan],\n",
    "    default=np.nan\n",
    ")\n",
    "\n",
    "# add column with pre accuracy and pre eeg info\n",
    "cleared_data_df['pre_acc'] = cleared_data_df['acc'].shift(1)\n",
    "cleared_data_df['pre_ne_Fz'] = cleared_data_df['ne_Fz'].shift(1)\n",
    "cleared_data_df['pre_ne_FCz'] = cleared_data_df['ne_FCz'].shift(1)\n",
    "cleared_data_df['pre_ne_mean_Fz'] = cleared_data_df['ne_mean_Fz'].shift(1)\n",
    "cleared_data_df['pre_ne_mean_FCz'] = cleared_data_df['ne_mean_FCz'].shift(1)\n",
    "\n",
    "# mark trials where rt exceed 1s\n",
    "cleared_data_df['rt_greater_than_1'] = cleared_data_df.apply(\n",
    "    lambda row: (True if row['rt'] > 1 else False),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate the mean(log(rt)) for each participant\n",
    "cleared_data_df['log_rt'] = np.log(cleared_data_df['rt'])\n",
    "participant_means = cleared_data_df.groupby('ID')['log_rt'].mean()\n",
    "participant_std = cleared_data_df.groupby('ID')['log_rt'].std()\n",
    "\n",
    "# mark trials that exceed rt threshold - participant-wise\n",
    "cleared_data_df['log_rt_exceed_threshold'], cleared_data_df['log_rt_exceed_ub'], cleared_data_df['log_rt_exceed_lb'] = zip(*cleared_data_df.apply(log_threshold, axis=1, args=(participant_means, participant_std)))\n",
    "\n",
    "\n",
    "global_log_rt = np.log(cleared_data_df['rt'].to_numpy())\n",
    "rt_upper_bound = np.nanmean(global_log_rt) + 3*np.nanstd(global_log_rt)\n",
    "rt_lower_bound = np.nanmean(global_log_rt) - 3*np.nanstd(global_log_rt)\n",
    "\n",
    "print(f\"Group-level RT upper bound: {np.exp(rt_upper_bound)}, RT lower bound: {np.exp(rt_lower_bound)}\")\n",
    "\n",
    "# mark trials that exceed rt threshold - globally\n",
    "cleared_data_df['global_log_rt_exceed_threshold'] = cleared_data_df.apply(\n",
    "    lambda row: (True if np.log(row['rt']) > rt_upper_bound or np.log(row['rt']) < rt_lower_bound else False),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Set 'rt' and 'reaction' to NaN if rt exceed 1s \n",
    "cleared_data_df.loc[cleared_data_df['rt_greater_than_1'] == True, ['rt', 'reaction']] = np.nan\n",
    "\n",
    "for idx, row in cleared_data_df.iterrows():\n",
    "    # mark if trial P is in CCX(P) sequence\n",
    "    if idx-3 >= 0:\n",
    "        if ((cleared_data_df.iloc[idx-3]['reaction'] == 'correct') and \n",
    "            (cleared_data_df.iloc[idx-2]['reaction'] == 'correct') and\n",
    "            (not pd.isna(cleared_data_df.iloc[idx-1]['ne_Fz'])) and\n",
    "            (not pd.isna(cleared_data_df.iloc[idx-1]['reaction'])) and\n",
    "            (not cleared_data_df.iloc[idx]['global_log_rt_exceed_threshold']) and\n",
    "            (not pd.isna(cleared_data_df.iloc[idx]['rt']))):\n",
    "                is_in_sequence = True\n",
    "        else:\n",
    "            is_in_sequence = False\n",
    "    else:\n",
    "        is_in_sequence = False\n",
    "\n",
    "    row_data = pd.DataFrame({\n",
    "        'trial_number': [row['trial_number']],\n",
    "        'ID': int(row['ID'].split(\"-\")[-1]),\n",
    "        'participant_index': [id_mapping[row['ID']]],\n",
    "        'condition': row['condition'],\n",
    "        'condition_index': [row['condition_index']],\n",
    "        'rt': row['rt'],\n",
    "        'acc': row['acc'],\n",
    "        'ne_Fz': row['ne_Fz'],\n",
    "        'ne_FCz': row['ne_FCz'],\n",
    "        'ne_mean_Fz': row['ne_mean_Fz'],\n",
    "        'ne_mean_FCz': row['ne_mean_FCz'],\n",
    "        'y':  row['rt'] *  row['acc'],\n",
    "        'pre_ne_Fz': row['pre_ne_Fz'],\n",
    "        'pre_ne_FCz': row['pre_ne_FCz'],\n",
    "        'pre_ne_mean_Fz': row['pre_ne_mean_Fz'],\n",
    "        'pre_ne_mean_FCz': row['pre_ne_mean_FCz'],\n",
    "        'pre_acc': row['pre_acc'],\n",
    "        'rt_greater_than_1': row['rt_greater_than_1'],\n",
    "        'log_rt_exceed_threshold': row['global_log_rt_exceed_threshold'],\n",
    "        'is_in_sequence': is_in_sequence,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    final_df = pd.concat([final_df, row_data], ignore_index=True)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbe9ab5556c2b9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 6. Center and standarize eeg signal participant-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b46623a63b96b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:46:16.835184Z",
     "start_time": "2024-06-11T12:46:16.520562Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def standardize(series):\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "final_df['pre_ne_FCz_standarized'] = final_df.groupby('ID')['pre_ne_FCz'].transform(standardize)\n",
    "\n",
    "# check the results of standardization\n",
    "final_df.groupby('ID').describe()['pre_ne_FCz_standarized']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2a9d67b10271c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 7. Create json file for Stan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a89f0df-45f2-4589-a9aa-14c94cd8c5b0",
   "metadata": {},
   "source": [
    "Leave only selected trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797628e83e6e201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:47:33.035311Z",
     "start_time": "2024-06-11T12:47:32.587664Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove trials with Nans\n",
    "df_no_nans = final_df.copy().dropna()\n",
    "\n",
    "# leave trials that are in CCXP sequence\n",
    "df_only_sequence = df_no_nans[df_no_nans['is_in_sequence'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc48ad-6850-46ac-9306-da1a0fec6d2e",
   "metadata": {},
   "source": [
    "Save data to pkl and csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bf5a4-8999-4ca0-ab44-cb42eb5e6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "df_only_sequence.to_pickle('../data/current_dataset/sonata_data_standardized.pkl')\n",
    "df_only_sequence.to_csv('../data/current_dataset/sonata_data_standardized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d88007-02d8-4b87-b44c-53daf6f3d001",
   "metadata": {},
   "source": [
    "Create json file for Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a2dcbf0455e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T15:17:14.408453Z",
     "start_time": "2024-04-22T15:17:14.155871Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y = df_only_sequence['y'].to_list()\n",
    "condition = df_only_sequence['condition'].to_list()\n",
    "pre_acc = df_only_sequence['pre_acc'].to_list()\n",
    "pre_ne = df_only_sequence['pre_ne_FCz_standarized'].to_list()\n",
    "participant_index = df_only_sequence['participant_index'].to_list()\n",
    "\n",
    "n_participants = len(np.unique(participant_index))\n",
    "n_conditions = len(np.unique(condition))\n",
    "\n",
    "participants_trials_slices = []\n",
    "for index in np.unique(participant_index):\n",
    "    indices = np.where(participant_index == index)[0]\n",
    "    start_index = int(indices[0] + 1)\n",
    "    end_index = int(indices[-1] + 1)\n",
    "    participants_trials_slices.append([start_index, end_index])\n",
    "\n",
    "# json\n",
    "data_2d = {\n",
    "    \"N\": len(y),\n",
    "    \"participants_trials_slices\": participants_trials_slices,\n",
    "    \"n_conditions\": n_conditions,\n",
    "    \"n_participants\": n_participants,\n",
    "    \"y\": y,\n",
    "    \"condition\": condition,\n",
    "    'pre_ne': pre_ne,\n",
    "    'pre_acc': pre_acc,\n",
    "    \"participant\": participant_index\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd33443ef178451",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Save data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0054f4b5586159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T15:17:19.558451Z",
     "start_time": "2024-04-22T15:17:19.443338Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../../data/current_dataset/sonata_data_standardized.json\", \"w\") as outfile: \n",
    "    json.dump(data_2d, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992cc9e-d3ee-44d1-b90a-0f6f4b27b130",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678276e8c9984d80",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1. Analyse the impact of trial selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8862473caaca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:30:06.351140Z",
     "start_time": "2024-04-22T16:30:06.070643Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mean_log_bad_trials = np.mean(cleared_data_df[cleared_data_df['log_rt_exceed_threshold'] == True].groupby('ID')['rt'].count().to_numpy().flatten())\n",
    "mean_global_log_bad_trials = np.mean(cleared_data_df[cleared_data_df['global_log_rt_exceed_threshold'] == True].groupby('ID')['rt'].count().to_numpy().flatten())\n",
    "global_log_bad_trials = cleared_data_df[cleared_data_df['global_log_rt_exceed_threshold'] == True].groupby('ID')['rt'].count()\n",
    "\n",
    "print(f'Average number of log(rt) exceeding the threshold per participant: {mean_log_bad_trials}')\n",
    "print(f'Average number of log(rt) exceeding the threshold per participant with global th: {mean_global_log_bad_trials}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0317fec52a049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:37:47.435340Z",
     "start_time": "2024-04-22T14:37:47.410165Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grouped_data = test_df[test_df['is_in_sequence'] == True].groupby(['ID', 'acc'])['rt'].count()\n",
    "group_with_error = grouped_data[grouped_data.index.get_level_values('acc') == -1]\n",
    "group_with_correct = grouped_data[grouped_data.index.get_level_values('acc') == 1]\n",
    "\n",
    "print(f'Average number of trials per participant with CCXP:\\n   error: {np.mean(group_with_error.reset_index()[\"rt\"].to_numpy())}\\n   correct:{np.mean(group_with_correct.reset_index()[\"rt\"].to_numpy())}')\n",
    "\n",
    "grouped_data_no_seq = test_df.groupby(['ID', 'acc'])['rt'].count()\n",
    "group_with_error_no_seq = grouped_data_no_seq[grouped_data_no_seq.index.get_level_values('acc') == -1]\n",
    "group_with_correct_no_seq = grouped_data_no_seq[grouped_data_no_seq.index.get_level_values('acc') == 1]\n",
    "\n",
    "print(f'Average number of trials per participant without CCXP:\\n   error: {np.mean(group_with_error_no_seq.reset_index()[\"rt\"].to_numpy())}\\n   correct:{np.mean(group_with_correct_no_seq.reset_index()[\"rt\"].to_numpy())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff5c7dc214b944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:38:05.484034Z",
     "start_time": "2024-04-22T14:38:05.412235Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cleared_data_df.groupby('ID')[['log_rt_exceed_lb','log_rt_exceed_ub' ]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c6f91-30ae-4e47-befa-7e7a09a98e96",
   "metadata": {},
   "source": [
    "#### Display thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577c3ad-2d2f-41b3-9d2b-b1eab02bd96f",
   "metadata": {},
   "source": [
    "- participant-wise threshold, e.g., ID = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b083a0b440828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:51:46.984827Z",
     "start_time": "2024-04-22T16:51:46.680003Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(cleared_data_df[cleared_data_df['ID'] == 'FLA-170']['rt'].to_numpy())\n",
    "m = np.nanmean(np.log(cleared_data_df[cleared_data_df['ID'] == 'FLA-170']['rt'].to_numpy()))\n",
    "sd = np.nanstd(np.log(cleared_data_df[cleared_data_df['ID'] == 'FLA-170']['rt'].to_numpy()))\n",
    "ub = np.exp(m + 3*sd)\n",
    "lb = np.exp(m - 3*sd)\n",
    "\n",
    "plt.axvline(x=ub, c='red')\n",
    "plt.axvline(x=lb, c='red')\n",
    "plt.annotate(f'{round(lb,2)}', (lb, 45))\n",
    "plt.annotate(f'{round(ub,2)}', (ub, 45))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd168a-48df-4baa-ae5e-903e7046c5cb",
   "metadata": {},
   "source": [
    "- global threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2e7b4dd0678bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:36:15.168038Z",
     "start_time": "2024-04-22T16:36:14.980369Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(cleared_data_df['rt'].to_numpy())\n",
    "m = np.nanmean(np.log(cleared_data_df['rt'].to_numpy()))\n",
    "sd = np.nanstd(np.log(cleared_data_df['rt'].to_numpy()))\n",
    "ub = np.exp(m + 3*sd)\n",
    "lb = np.exp(m - 3*sd)\n",
    "\n",
    "plt.axvline(x=ub, c='red')\n",
    "plt.axvline(x=lb, c='red')\n",
    "plt.annotate(f'{round(lb,2)}', (lb, 45))\n",
    "plt.annotate(f'{round(ub,2)}', (ub, 45))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4372c09690f0366",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2. Post-error adaptation in RT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f8702-3c77-4d45-a62b-a6aed86ceb7c",
   "metadata": {},
   "source": [
    "Group-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115f2707c7a7581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:38:34.303041Z",
     "start_time": "2024-04-22T14:38:33.044340Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    test_df,\n",
    "    x='rt',\n",
    "    hue=test_df[['condition', 'pre_acc']].apply(tuple, axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8875cea-0791-4df3-b5d5-62dba6ea99cd",
   "metadata": {},
   "source": [
    "Participant-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cf33a445d799a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:26:08.790838Z",
     "start_time": "2024-04-22T16:25:38.940183Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    cleared_data_df.sort_values(['ID']),\n",
    "    col=\"ID\",\n",
    "    col_wrap=3,\n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    "    aspect=2,\n",
    ")\n",
    "\n",
    "g.map_dataframe(\n",
    "    sns.histplot,\n",
    "    x=\"rt\",\n",
    "    hue='pre_response',\n",
    "    kde=True,\n",
    "    palette='colorblind'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe80b9ef455459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:38:43.698691Z",
     "start_time": "2024-04-22T14:38:43.687209Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Mean post error RT: {np.mean(test_df[test_df['pre_acc'] == -1]['rt'])}\")\n",
    "print(f\"Mean post correct RT: {np.mean(test_df[test_df['pre_acc'] == 1]['rt'])}\")\n",
    "\n",
    "print(f\"Mean incongruent post error RT: {np.mean(test_df[(test_df['pre_acc'] == -1) & (test_df['condition'] == -1)]['rt'])}\")\n",
    "print(f\"Mean incongruent post correct RT: {np.mean(test_df[(test_df['pre_acc'] == 1) & (test_df['condition'] == -1)]['rt'])}\")\n",
    "\n",
    "print(f\"Mean congruent post error RT: {np.mean(test_df[(test_df['pre_acc'] == -1) & (test_df['condition'] == 1)]['rt'])}\")\n",
    "print(f\"Mean congruent post correct RT: {np.mean(test_df[(test_df['pre_acc'] == 1) & (test_df['condition'] == 1)]['rt'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf0b156f1b0a5af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T14:38:47.678960Z",
     "start_time": "2024-04-22T14:38:47.654838Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "print(f\"post error vs post correct : {ttest_ind(test_df[test_df['pre_acc'] == -1]['rt'], test_df[test_df['pre_acc'] == 1]['rt'])}\")\n",
    "print(f\"post error vs post correct in incongruent: {ttest_ind(test_df[(test_df['pre_acc'] == -1) & (test_df['condition'] == -1)]['rt'], test_df[(test_df['pre_acc'] == 1) & (test_df['condition'] == -1)]['rt'])}\")\n",
    "\n",
    "print(f\"post error vs post correct in congruent: {ttest_ind(test_df[(test_df['pre_acc'] == -1) & (test_df['condition'] == 1)]['rt'], test_df[(test_df['pre_acc'] == 1) & (test_df['condition'] == 1)]['rt'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da313e95fc523a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Test post-response adaptation and links with pre-trial accuracy and brain signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc1ba9e11c2d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T22:01:29.728139Z",
     "start_time": "2024-02-05T22:01:29.576223Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "test_df2 = test_df.dropna()\n",
    "test_df2['rt'] = test_df2['rt']*1000\n",
    "test_df2['pre_ne_FCz_centered'] = test_df2['pre_ne_FCz'] - np.mean(test_df2['pre_ne_FCz'])\n",
    "\n",
    "mod = smf.ols(formula='rt ~ pre_ne_FCz_centered*pre_acc', data=test_df2)\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
